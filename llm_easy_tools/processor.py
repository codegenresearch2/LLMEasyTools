import json\\nimport inspect\\nimport traceback\\n\\nfrom concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\\nfrom typing import Callable, Union, Optional, Any, get_origin, get_args\\nfrom pprint import pprint\\n\\nfrom pydantic import BaseModel, ValidationError\\nfrom dataclasses import dataclass, field\\n\\nfrom llm_easy_tools.schema_generator import get_name, parameters_basemodel_from_function, LLMFunction\\nfrom llm_easy_tools.types import ChatCompletion, ChatCompletionMessageToolCall, ChatCompletionMessage, ChatCompletionMessageToolCall, Function\\n\\nclass NoMatchingTool(Exception):\\n    def __init__(self, message):\\n        self.message = message\\n        super().__init__(self.message)\\n\\n@dataclass\\nclass ToolResult:\\n    \"\"\"\\n    Represents the result of a tool invocation within the ToolBox framework.\\n    \"\"\"\\n    tool_call_id: str\\n    name: str\\n    output: Optional[Any] = None\\n    arguments: Optional[dict[str, Any]] = None\\n    error: Optional[Exception] = None\\n    stack_trace: Optional[str] = None\\n    soft_errors: list[Exception] = field(default_factory=list)\\n    prefix: Optional[BaseModel] = None\\n    tool: Optional[Union[Callable, BaseModel]] = None\\n\\n    def to_message(self) -> dict[str, str]:\\n        if self.error is not None:\\n            content = f"{self.error}\\n        elif self.output is None:\\n            content = ''\\n        elif isinstance(self.output, BaseModel):\\n            content = f"{self.name} created\\n        else:\\n            content = str(self.output)\\n        return {\"role\": \"tool\", \"tool_call_id\": self.tool_call_id, \"name\": self.name, \"content\": content}\\n\\ndef process_tool_call(tool_call, functions_or_models, prefix_class=None, fix_json_args=True, case_insensitive=False) -> ToolResult:\\n    function_call = tool_call.function\\n    tool_name = function_call.name\\n    args = function_call.arguments\\n    soft_errors: list[Exception] = []\\n    error = None\\n    stack_trace = None\\n    prefix = None\\n    output = None\\n    try:\\n        tool_args = json.loads(args)\\n    except json.decoder.JSONDecodeError as e:\\n        if fix_json_args:\\n            soft_errors.append(e)\\n            args = args.replace(', }', '}').replace(',}', '}')\\n            tool_args = json.loads(args)\\n        else:\\n            stack_trace = traceback.format_exc()\\n            return ToolResult(tool_call_id=tool_call.id, name=tool_name, error=e, stack_trace=stack_trace)\\n\\n    if prefix_class is not None:\\n        try:\\n            prefix = _extract_prefix_unpacked(tool_args, prefix_class)\\n        except ValidationError as e:\\n            soft_errors.append(e)\\n        prefix_name = prefix_class.__name__\\n        if case_insensitive:\\n            prefix_name = prefix_name.lower()\\n        if not tool_name.startswith(prefix_name):\\n            soft_errors.append(NoMatchingTool(f"Trying to decode function call with a name '{tool_name}' not matching prefix '{prefix_name}'"))\n        else:\\n            tool_name = tool_name[len(prefix_name + '_and_'):]\n\\n    tool = None\\n\\n    for f in functions_or_models:\\n        if get_name(f, case_insensitive=case_insensitive) == tool_name:\\n            tool = f\\n            try:\\n                output, new_soft_errors = _process_unpacked(f, tool_args, fix_json_args=fix_json_args)\\n                soft_errors.extend(new_soft_errors)\\n            except Exception as e:\\n                error = e\\n                stack_trace = traceback.format_exc()\\n            break\\n    else:\\n        error = NoMatchingTool(f"Function {tool_name} not found")\\n    result = ToolResult(\\n        tool_call_id=tool_call.id, \\n        name=tool_name,\\n        arguments=tool_args, \\n        output=output, \\n        error=error, \\n        stack_trace=stack_trace, \\n        soft_errors=soft_errors, \\n        prefix=prefix, \\n        tool=tool, \\n    )\\n    return result\\n\\ndef split_string_to_list(s: str) -> list[str]:\\n    try:\\n        return json.loads(s)\\n    except json.JSONDecodeError:\\n        return [item.strip() for item in s.split(',')]\n\\ndef _process_unpacked(function, tool_args={}, fix_json_args=True):\\n    if isinstance(function, LLMFunction):\\n        function = function.func\\n    model = parameters_basemodel_from_function(function)\\n    soft_errors = []\\n    if fix_json_args:\\n        for field, field_info in model.model_fields.items():\\n            field_annotation = field_info.annotation\\n            if _is_list_type(field_annotation):\\n                if field in tool_args and isinstance(tool_args[field], str):\\n                    tool_args[field] = split_string_to_list(tool_args[field])\\n                    soft_errors.append(f"Fixed JSON decode error for field {field}")\\n\\n    model_instance = model(**tool_args)\\n    args = {}\\n    for field, _ in model.model_fields.items():\\n        args[field] = getattr(model_instance, field)\\n    return function(**args), soft_errors\\n\\ndef _is_list_type(annotation):\\n    origin = get_origin(annotation)\\n    args = get_args(annotation)\\n\\n    if origin is list:\\n        return True\\n    elif origin is Union or origin is Optional:\\n        return any(_is_list_type(arg) for arg in args)\\n    return False\\n\\ndef _extract_prefix_unpacked(tool_args, prefix_class):\\n    prefix_args = {}\\n    for key in list(tool_args.keys()):  # copy keys to list because we modify the dict while iterating over it\\n        if key in prefix_class.__annotations__:\\n            prefix_args[key] = tool_args.pop(key)\\n    prefix = prefix_class(**prefix_args)\\n    return prefix\\n\\ndef process_response(response: ChatCompletion, functions: list[Union[Callable, LLMFunction]], choice_num=0, **kwargs) -> list[ToolResult]:\\n    \"\"\"\\n    Processes a ChatCompletion response, executing contained tool calls.\\n    For each tool call matches a function from the 'functions' list by name.\\n    The result of the tool call is returned as a ToolResult object.\\n    If the tool call raises an exception, that exception is saved in the 'error' field in the result.\\n    \"\"\"\\n    message = response.choices[choice_num].message\\n    return process_message(message, functions, **kwargs)\\n\\ndef process_message(\\n    message: ChatCompletionMessage, \\n    functions: list[Union[Callable, LLMFunction]], \\n    prefix_class=None, \\n    fix_json_args=True, \\n    case_insensitive=False, \\n    executor: Union[ThreadPoolExecutor, ProcessPoolExecutor, None]=None\\n    ) -> list[ToolResult]:\\n    results = []\\n    if hasattr(message, 'function_call') and (function_call:=message.function_call):\\n        tool_calls = [ChatCompletionMessageToolCall(id='A', function=Function(name=function_call.name, arguments=function_call.arguments), type='function')]\n    elif hasattr(message, 'tool_calls') and message.tool_calls:\\n        tool_calls = message.tool_calls\\n    else:\\n        tool_calls = []\\n    if not tool_calls:\\n        return []\\n    args_list = [(tool_call, functions, prefix_class, fix_json_args, case_insensitive) for tool_call in tool_calls]\n\\n    if executor:\\n        results = list(executor.map(lambda args: process_tool_call(*args), args_list))\n    else:\\n        results = list(map(lambda args: process_tool_call(*args), args_list))\n    return results\\n\\ndef process_one_tool_call(\\n        response: ChatCompletion, \\n        functions: list[Union[Callable, LLMFunction]], \\n        index: int = 0, \\n        prefix_class=None, \\n        fix_json_args=True, \\n        case_insensitive=False\\n    ) -> Optional[ToolResult]:\\n    \"\"\"\\n    Processes a single tool call from a ChatCompletion response at the specified index.\\n    \"\"\"\\n    tool_calls = _get_tool_calls(response)\\n    if not tool_calls or index >= len(tool_calls):\\n        return None\\n\\n    return process_tool_call(tool_calls[index], functions, prefix_class, fix_json_args, case_insensitive)\\n\\n# Helper function to get tool calls from the response\\ndef _get_tool_calls(response: ChatCompletion) -> list[ChatCompletionMessageToolCall]:\\n    if hasattr(response.choices[0].message, 'function_call') and (function_call := response.choices[0].message.function_call):\\n        return [ChatCompletionMessageToolCall(id='A', function=Function(name=function_call.name, arguments=function_call.arguments), type='function')]\n    elif hasattr(response.choices[0].message, 'tool_calls') and response.choices[0].message.tool_calls:\\n        return response.choices[0].message.tool_calls\\n    return []\\n\\n########################################\\n#\\n# Examples\\n\\nif __name__ == "__main__":\\n    from llm_easy_tools.types import mk_chat_with_tool_call\\n\\n    def original_function():\\n        return 'Result of function_decorated'\\n\\n    function_decorated = LLMFunction(original_function, name="altered_name")\\n\\n    class ExampleClass:\\n        def simple_method(self, count: int, size: float):\\n            \"""simple method does something\"\""\\n            return 'Result of simple_method'\\n\\n    example_object = ExampleClass()\\n\\n    class User(BaseModel):\\n        name: str\\n        email: str\\n\\n    pprint(process_response(mk_chat_with_tool_call('altered_name', {}), [function_decorated]))\\n    call_to_altered_name = mk_chat_with_tool_call('altered_name', {}).choices[0].message.tool_calls[0]\\n    pprint(call_to_altered_name)\\n    pprint(process_tool_call(call_to_altered_name, [function_decorated]))\\n\\n    call_to_simple_method = mk_chat_with_tool_call('simple_method', {"count": 1, "size": 2.2}).choices[0].message.tool_calls[0]\\n    pprint(process_tool_call(call_to_simple_method, [example_object.simple_method]))\\n\\n    call_to_model = mk_chat_with_tool_call('User', {"name": 'John', "email": 'john@example.com'}).choices[0].message.tool_calls[0]\\n    pprint(process_tool_call(call_to_model, [User]))